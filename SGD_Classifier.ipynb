{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# You can check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "2d6294f5-29ed-4bd1-aa15-c23535a21d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DR_YMBsyOci",
    "outputId": "318fc431-6a68-4ae1-cb65-c6fbf1cf52f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "9e494756-e8f8-4732-90a3-ce300d482e42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "2c8caa3d-31f5-42f5-b919-3d96f91b7d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.11 seconds.\n",
      "Convergence after 10 epochs took 0.11 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "6c760a9a-ecd3-48d5-9546-27b07ceb0c96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "## <font color='red' size=5> Implementing Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initializing the weight_vector and intercept term to zeros (Code written in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Created a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (kept batch size=1)\n",
    "\n",
    "        - Calculated the gradient of loss function w.r.t each weight in weight vector (Code written in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculated the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Updated weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - Calculated the log loss for train and test with the updated weights\n",
    "    - Appended this loss in the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #used zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialized bias to zero\n",
    "    w = np.zeros(len(dim))\n",
    "    b=0\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7I6uWBRsKc4",
    "outputId": "7b9d55c4-2a79-447f-ec84-e7255e2bd4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0]\n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_sDqi1kO2zx",
    "outputId": "cbcdc34c-5206-4709-b8be-930750728d54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1/(1+math.exp(-2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # computed sigmoid(z) and return\n",
    "    s = 1/(1+math.exp(-z))\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    sum=0\n",
    "    for i in range(len(y_true)):\n",
    "        sum=sum+((y_true[i]*math.log(y_pred[i],10)) + ((1-y_true[i])*math.log((1-y_pred[i]),10)))\n",
    "    \n",
    "    loss = -1*(1/len(y_true))*sum\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x*(y-sigmoid(w@x + b)) - (alpha/N)*w\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "     db = y - sigmoid(w@x + b)\n",
    "\n",
    "     return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    #implementing the code as follows\n",
    "    # initalizing the weights (call the initialize_weights(X_train[0]) function)\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    grad_w,grad_b=initialize_weights(X_train[0])\n",
    "    # for every epoch\n",
    "    for i in range(epochs):\n",
    "        # for every data point(X_train,y_train)\n",
    "        for j in range(len(X_train)):\n",
    "           #computing gradient w.r.to w (call the gradient_dw() function)\n",
    "           grad_dw=gradient_dw(X_train[j],y_train[j],grad_w,grad_b,alpha,N)\n",
    "           #computing gradient w.r.to b (call the gradient_db() function)\n",
    "           grad_db=gradient_db(X_train[j],y_train[j],grad_w,grad_b)\n",
    "           #update w, b\n",
    "           grad_w = grad_w + eta0*grad_dw\n",
    "           grad_b = grad_b + eta0*grad_db\n",
    "\n",
    "        # predicting the output of x_train[for all data points in X_train] using w,b\n",
    "        y_pred_train = X_train.dot(grad_w) + grad_b\n",
    "        y_pred_train = np.array([0.1 if sigmoid(i)>=0 and sigmoid(i)<0.1 else round(sigmoid(i),1) for i in y_pred_train])\n",
    "        for i in range(len(y_pred_train)):\n",
    "            if(y_pred_train[i] == 1):\n",
    "                y_pred_train[i] =0.9  #while calculating log-loss log(1) = 0, & log(1-1) = log(0) = infinite. \n",
    "        #y_pred_train = [0 if i<0.5 else 1 for i in y_pred_train]\n",
    "        #computing the loss between predicted and actual values (call the loss function)\n",
    "        loss = logloss(y_train,y_pred_train)\n",
    "        # storing all the train loss values in a list\n",
    "        train_loss_list.append(loss)\n",
    "        # predicting the output of x_test[for all data points in X_test] using w,b\n",
    "        y_pred_test = X_test@grad_w + grad_b\n",
    "        y_pred_test = np.array([0.1 if sigmoid(i)>=0 and sigmoid(i)<0.1 else round(sigmoid(i),1) for i in y_pred_test])\n",
    "        for i in range(len(y_pred_test)):\n",
    "            if(y_pred_test[i] == 1):\n",
    "                y_pred_test[i] =0.9\n",
    "        #computing the loss between predicted and actual values (call the loss function)\n",
    "        loss = logloss(y_test,y_pred_test)\n",
    "        # storing all the test loss values in a list\n",
    "        test_loss_list.append(loss)\n",
    "        \n",
    "    return grad_w,grad_b,train_loss_list,test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=50\n",
    "w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of Project</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Comparing my implementation and SGDClassifier's weights and intercept, making sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nx8Rs9rfEZ1R",
    "outputId": "2284df77-4fbf-4b00-9702-a2af985bf578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00642552,  0.00755955,  0.00012041, -0.00335043, -0.01309563,\n",
       "          0.00978314,  0.00724319,  0.00418409,  0.0125563 , -0.00701162,\n",
       "          0.00169655, -0.00480346, -0.00173041,  0.00056208,  0.00032075]]),\n",
       " array([-0.03911387]))"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "1O6GrRt7UeCJ",
    "outputId": "470859c6-2948-4c79-841e-7b17fa1c1f22"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = np.arange(50)\n",
    "plt.plot(epochs, train_loss, label='Train loss')\n",
    "plt.plot(epochs, test_loss, label='Test loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Train loss Vs Test loss Plot\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUN8puFoEZtU",
    "outputId": "e6e140c8-7496-474d-de12-71a8f2232fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9522133333333334\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
